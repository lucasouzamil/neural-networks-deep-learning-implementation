{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e077c6ef",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "### **Data Generation Task:** \n",
    "\n",
    "Generate two classes of 2D data points (1000 samples per class) using multivariate normal distributions. Use the following parameters:  \n",
    "\n",
    "- Class 0:\n",
    "\n",
    "    Mean = $[2, 2]$,\n",
    "    \n",
    "    Covariance matrix = $[[0.5, 0], [0, 0.5]]$ (i.e., variance of $0.5$ along each dimension, no covariance).  \n",
    "\n",
    "- Class 1:\n",
    "\n",
    "    Mean = $[5, 5]$,\n",
    "    \n",
    "    Covariance matrix = $[[0.5, 0], [0, 0.5]]$.  \n",
    "\n",
    "These parameters ensure the classes are mostly linearly separable, with minimal overlap due to the distance between means and low variance. Plot the data points (using libraries like matplotlib if desired) to visualize the separation, coloring points by class.\n",
    "\n",
    "### **Perceptron Implementation Task:**\n",
    "\n",
    "Implement a single-layer perceptron from scratch to classify the generated data into the two classes. You may use NumPy only for basic linear algebra operations (e.g., matrix multiplication, vector addition/subtraction, dot products). Do not use any pre-built machine learning libraries (e.g., no scikit-learn) or NumPy functions that directly implement perceptron logic.  \n",
    "\n",
    "- Initialize weights (w) as a 2D vector (plus a bias term b).  \n",
    "- Use the perceptron learning rule: For each misclassified sample $(x, y)$, update $w = w + η * y * x$ and $b = b + η * y$, where $η$ is the learning rate (start with $η=0.01$).  \n",
    "- Train the model until convergence (no weight updates occur in a full pass over the dataset) or for a maximum of 100 epochs, whichever comes first. If convergence is not achieved by 100 epochs, report the accuracy at that point. Track accuracy after each epoch.  \n",
    "- After training, evaluate accuracy on the full dataset and plot the decision boundary (line defined by $w·x + b = 0$) overlaid on the data points. Additionally, plot the training accuracy over epochs to show convergence progress. Highlight any misclassified points in a separate plot or by different markers in the decision boundary plot.  \n",
    "\n",
    "Report the final weights, bias, accuracy, and discuss why the data's separability leads to quick convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21c88c9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efc196e9",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "### **Data Generation Task:**  \n",
    "\n",
    "Generate two classes of 2D data points (1000 samples per class) using multivariate normal distributions. Use the following parameters:\n",
    "\n",
    "- Class 0:\n",
    "\n",
    "    Mean = $[3, 3]$,\n",
    "\n",
    "    Covariance matrix = $[[1.5, 0], [0, 1.5]]$ (i.e., higher variance of 1.5 along each dimension).\n",
    "\n",
    "- Class 1:\n",
    "\n",
    "    Mean = $[4, 4]$,\n",
    "\n",
    "    Covariance matrix = $[[1.5, 0], [0, 1.5]]$.  \n",
    "\n",
    "These parameters create partial overlap between classes due to closer means and higher variance, making the data not fully linearly separable. Plot the data points to visualize the overlap, coloring points by class.\n",
    "\n",
    "### **Perceptron Implementation Task:**  \n",
    "\n",
    "Using the same implementation guidelines as in Exercise 1, train a perceptron on this dataset.  \n",
    "\n",
    "- Follow the same initialization, update rule, and training process.  \n",
    "- Train the model until convergence (no weight updates occur in a full pass over the dataset) or for a maximum of 100 epochs, whichever comes first. If convergence is not achieved by 100 epochs, report the accuracy at that point and note any oscillation in updates; consider reporting the best accuracy achieved over multiple runs (e.g., average over 5 random initializations). Track accuracy after each epoch.  \n",
    "- Evaluate accuracy after training and plot the decision boundary overlaid on the data points. Additionally, plot the training accuracy over epochs to show convergence progress (or lack thereof). Highlight any misclassified points in a separate plot or by different markers in the decision boundary plot.  \n",
    "\n",
    "Report the final weights, bias, accuracy, and discuss how the overlap affects training compared to Exercise 1 (e.g., slower convergence or inability to reach 100% accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803642f2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
